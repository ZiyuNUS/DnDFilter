project_name: state_image
run_name: state_image

# training setup
use_wandb: true # set to false if you don't want to log to wandb
train: true
batch_size: 94
eval_batch_size: 94
epochs: 300
gpu_ids: [0]
num_workers: 1
lr: 1e-4
optimizer: adamw
clipping: False
max_norm: 1.
scheduler: "cosine"
warmup: True
warmup_epochs: 4
seed: 0
load_run: state_image/VinT(w.o. pred)

training_setting: "VinT_wo_pred"
use_gt: 0

# model params
vision_encoder: VinT(w.o. pred)
encoding_size: 256
obs_encoder: efficientnet-b0
attn_unet: False
cond_predict_scale: False
mha_num_attention_heads: 4
mha_num_attention_layers: 4
mha_ff_dim_factor: 4
down_dims: [64, 128, 256]

# diffusion model params
num_diffusion_iters: 10

# normalization for the action space
normalize: True

# context
context_type: temporal
context_size: 3 # 5
visual_size: 3 # 3+1

# action output params
len_traj_pred: 4

# dataset specific parameters
image_size: [128, 128] # width, height
datasets:
  RED:
    train_data_folder: dataset/circles=100_frames=100_noise=True/train=500
    test_data_folder: dataset/circles=100_frames=100_noise=True/test=100
    train: DND_train/data/data_splits/RED_96_100/train/
    test: DND_train/data/data_splits/RED_96_100/test/
    end_slack: 0
    negative_mining: True
    record_spacing : 2

# logging stuff
## =0 turns off
print_log_freq: 1 # in iterations
pairwise_test_freq: 0 # in epochs
eval_fraction: 0.5
wandb_log_freq: 1 # in iterations
eval_freq: 2 # in epochs